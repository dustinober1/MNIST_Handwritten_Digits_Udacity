# ğŸ”¢ MNIST Handwritten Digit Classifier

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF6B6B?logo=streamlit&logoColor=white)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

A modern, production-ready implementation of handwritten digit classification using deep learning. This project features a custom neural network trained on the MNIST dataset with a sleek Streamlit web interface for real-time predictions.

## âœ¨ Features

- **ğŸ§  Custom Neural Network**: Improved architecture achieving 97%+ accuracy
- **ğŸ–¼ï¸ Interactive Web App**: Upload images or draw digits with real-time predictions
- **ğŸ“Š Comprehensive Evaluation**: Detailed metrics, confusion matrices, and visualizations
- **ğŸ”§ Professional Codebase**: Modular design, type hints, comprehensive testing
- **ğŸ“¦ Easy Deployment**: Docker support and CLI tools
- **ğŸš€ CI/CD Ready**: GitHub Actions integration

## ğŸ“‹ Table of Contents

- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“ Project Structure](#-project-structure)
- [âš™ï¸ Installation](#ï¸-installation)
- [ğŸ¯ Usage](#-usage)
  - [Web Interface](#web-interface)
  - [Command Line](#command-line)
  - [Jupyter Notebook](#jupyter-notebook)
- [ğŸ§  Model Architecture](#-model-architecture)
- [ğŸ“Š Evaluation & Metrics](#-evaluation--metrics)
- [ğŸ§ª Testing](#-testing)
- [ğŸ³ Docker Deployment](#-docker-deployment)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/mnist-digit-classifier.git
cd mnist-digit-classifier

# Install dependencies
pip install -r requirements.txt

# Train the model (optional - pre-trained model included)
python scripts/train.py --epochs 10 --evaluate

# Launch the web interface
streamlit run app.py
```

Open your browser to `http://localhost:8501` and start classifying digits!

## ğŸ“ Project Structure

```
mnist-digit-classifier/
â”œâ”€â”€ ğŸ“ src/mnist_classifier/     # Core package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                 # Neural network architectures  
â”‚   â”œâ”€â”€ preprocessing.py         # Image preprocessing utilities
â”‚   â”œâ”€â”€ utils.py                 # Helper functions
â”‚   â””â”€â”€ evaluation.py            # Model evaluation and metrics
â”œâ”€â”€ ğŸ“ scripts/                  # Command-line tools
â”‚   â”œâ”€â”€ train.py                 # Training script
â”‚   â””â”€â”€ evaluate.py              # Evaluation script
â”œâ”€â”€ ğŸ“ tests/                    # Unit tests
â”‚   â”œâ”€â”€ test_model.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ ğŸ“ docs/                     # Documentation
â”œâ”€â”€ app.py                       # Streamlit web interface
â”œâ”€â”€ MNIST_Handwritten_Digits.ipynb # Jupyter notebook
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ Dockerfile                   # Container configuration
â””â”€â”€ README.md                    # You are here!
```

## âš™ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/mnist-digit-classifier.git
   cd mnist-digit-classifier
   ```

2. **Create a virtual environment (recommended):**
   ```bash
   python -m venv mnist-env
   source mnist-env/bin/activate  # On Windows: mnist-env\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

### Verify Installation
```bash
# Run tests to verify everything is working
pytest tests/ -v

# Check if CUDA is available (optional)
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

## ğŸ¯ Usage

### Web Interface

Launch the interactive Streamlit app:

```bash
streamlit run app.py
```

Features:
- ğŸ“¤ **Upload images**: Drag and drop or browse for digit images
- âœï¸ **Draw digits**: Use the interactive canvas to draw your own digits
- ğŸ“Š **Real-time predictions**: Get instant results with confidence scores
- ğŸ“ˆ **Visualization**: Beautiful charts showing prediction confidence

### Command Line

#### Training
```bash
# Basic training
python scripts/train.py

# Advanced training with custom parameters
python scripts/train.py --epochs 15 --batch-size 128 --learning-rate 0.0005 --augment --evaluate

# Train different model architectures
python scripts/train.py --model simple  # or --model improved
```

#### Evaluation
```bash
# Evaluate a trained model
python scripts/evaluate.py --model-path mnist_model.pth --output-dir results/
```

#### Available Options
- `--epochs`: Number of training epochs (default: 10)
- `--batch-size`: Training batch size (default: 64)
- `--learning-rate`: Learning rate for optimizer (default: 0.001)
- `--augment`: Enable data augmentation
- `--evaluate`: Run comprehensive evaluation after training
- `--device`: Use 'cpu', 'cuda', or 'auto'

### Jupyter Notebook

Explore the complete workflow in the interactive notebook:

```bash
jupyter notebook MNIST_Handwritten_Digits.ipynb
```

## ğŸ§  Model Architecture

### ImprovedMNISTNet

Our custom neural network achieves **97%+ accuracy** on the MNIST test set:

```
Input (28Ã—28 pixels) â†’ Flatten (784 features)
     â†“
FC Layer 1: 784 â†’ 256 neurons + ReLU
     â†“  
FC Layer 2: 256 â†’ 128 neurons + ReLU
     â†“
FC Layer 3: 128 â†’ 64 neurons + ReLU
     â†“
Output Layer: 64 â†’ 10 classes (digits 0-9)
```

**Key Features:**
- ğŸ¯ **Xavier Weight Initialization**: For stable training
- ğŸ”„ **ReLU Activation**: Fast and effective non-linearity
- ğŸ“‰ **CrossEntropyLoss**: Optimized for multi-class classification
- âš¡ **Adam Optimizer**: Adaptive learning rate

### Preprocessing Pipeline

1. **Grayscale Conversion**: Ensures single-channel input
2. **Resize to 28Ã—28**: Matches MNIST format
3. **Tensor Conversion**: PIL Image â†’ PyTorch Tensor
4. **Normalization**: Pixel values scaled to [-1, 1] for stability
5. **Data Augmentation** (training only): Random rotations and translations

## ğŸ“Š Evaluation & Metrics

Comprehensive model evaluation includes:

- **ğŸ“ˆ Accuracy Metrics**: Overall and per-class accuracy
- **ğŸ¯ Confusion Matrix**: Detailed misclassification analysis  
- **ğŸ“Š Precision/Recall/F1**: Per-digit performance metrics
- **ğŸ“‰ Confidence Analysis**: Prediction certainty distributions
- **ğŸ” Error Analysis**: Common misclassification patterns

### Sample Results

| Metric | Value |
|--------|-------|
| Test Accuracy | 97.2% |
| Precision | 97.1% |
| Recall | 97.2% |
| F1-Score | 97.1% |

Run evaluation to generate detailed reports:

```bash
python scripts/evaluate.py --model-path mnist_model.pth
```

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Run all tests
pytest tests/ -v

# Run specific test categories
pytest tests/test_model.py -v          # Model architecture tests
pytest tests/test_preprocessing.py -v   # Data preprocessing tests  
pytest tests/test_utils.py -v          # Utility function tests

# Generate coverage report
pytest tests/ --cov=src/mnist_classifier --cov-report=html
```

## ğŸ³ Docker Deployment

### Build and Run

```bash
# Build the Docker image
docker build -t mnist-classifier .

# Run the container
docker run -p 8501:8501 mnist-classifier
```

### Docker Compose (with GPU support)

```bash
docker-compose up
```

Access the app at `http://localhost:8501`

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup

```bash
# Clone your fork
git clone https://github.com/yourusername/mnist-digit-classifier.git
cd mnist-digit-classifier

# Install development dependencies
pip install -r requirements.txt
pip install -e .

# Run pre-commit hooks
pre-commit install

# Run tests
pytest tests/ -v
```

### Code Quality

We use:
- **Black**: Code formatting
- **Flake8**: Linting  
- **Pytest**: Testing
- **Type hints**: For better code documentation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements

- **MNIST Dataset**: Created by Yann LeCun and collaborators
- **PyTorch**: The deep learning framework that powers our models
- **Streamlit**: For the amazing web app framework
- **scikit-learn**: For evaluation metrics and utilities

---

â­ **Star this repository if you found it helpful!**

ğŸ“§ **Questions?** Feel free to open an issue or reach out!

ğŸš€ **Want to contribute?** Check out our [contributing guidelines](#-contributing)!